{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask, concurrent.futures, time, warnings, os, re, pickle\n",
    "from osgeo import gdal\n",
    "import requests as r\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "import param as pm\n",
    "import pandas as pd\n",
    "from collections import OrderedDict as odict\n",
    "import numpy as np\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse,fromstring\n",
    "from affine import Affine\n",
    "from pandas import to_datetime\n",
    "import jinja2 as jj2\n",
    "from rasterio.crs import CRS\n",
    "from tempfile import NamedTemporaryFile\n",
    "from datetime import datetime\n",
    "from netrc import netrc\n",
    "from subprocess import Popen\n",
    "from pyproj import Proj\n",
    "from src.hls_funcs.masks import mask_hls\n",
    "from src.hls_funcs.predict import pred_cov, pred_bm, pred_bm_se, pred_bm_thresh\n",
    "import cartopy.crs as ccrs\n",
    "from bokeh.models.formatters import PrintfTickFormatter\n",
    "import stackstac\n",
    "from subprocess import Popen, DEVNULL, STDOUT\n",
    "from getpass import getpass\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LUT dict including the HLS product bands mapped to names\n",
    "lut = {'HLSS30':\n",
    "       {'B01': 'COASTAL-AEROSOL',\n",
    "        'B02': 'BLUE', \n",
    "        'B03': 'GREEN', \n",
    "        'B04': 'RED', \n",
    "        'B05': 'RED-EDGE1',\n",
    "        'B06': 'RED-EDGE2', \n",
    "        'B07': 'RED-EDGE3',\n",
    "        'B08': 'NIR-Broad',\n",
    "        'B8A': 'NIR1', \n",
    "        'B09': 'WATER-VAPOR',\n",
    "        'B10': 'CIRRUS',\n",
    "        'B11': 'SWIR1', \n",
    "        'B12': 'SWIR2', \n",
    "        'Fmask': 'FMASK'},\n",
    "       'HLSL30': \n",
    "       {'B01': 'COASTAL-AEROSOL',\n",
    "        'B02': 'BLUE', \n",
    "        'B03': 'GREEN', \n",
    "        'B04': 'RED', \n",
    "        'B05': 'NIR1',\n",
    "        'B06': 'SWIR1',\n",
    "        'B07': 'SWIR2', \n",
    "        'B09': 'CIRRUS', \n",
    "        'B10': 'TIR1', \n",
    "        'B11': 'TIR2', \n",
    "        'Fmask': 'FMASK'}}\n",
    "\n",
    "# List of all available/acceptable band names\n",
    "all_bands = ['ALL', 'COASTAL-AEROSOL', 'BLUE', 'GREEN', 'RED', 'RED-EDGE1', 'RED-EDGE2', 'RED-EDGE3', \n",
    "             'NIR1', 'SWIR1', 'SWIR2', 'CIRRUS', 'TIR1', 'TIR2', 'WATER-VAPOR', 'FMASK']\n",
    "\n",
    "needed_bands = ['BLUE', 'GREEN', 'RED', 'NIR1', 'SWIR1', 'SWIR2', 'FMASK']\n",
    "\n",
    "d_bounds = (datetime(2019, 1, 1), datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NASA_CMR_STAC(hls_data, aws):\n",
    "    stac = 'https://cmr.earthdata.nasa.gov/stac/' # CMR-STAC API Endpoint\n",
    "    stac_response = r.get(stac).json()            # Call the STAC API endpoint\n",
    "    stac_lp = [s for s in stac_response['links'] if 'LP' in s['title']]  # Search for only LP-specific catalogs\n",
    "\n",
    "    # LPCLOUD is the STAC catalog we will be using and exploring today\n",
    "    lp_cloud = r.get([s for s in stac_lp if s['title'] == 'LPCLOUD'][0]['href']).json()\n",
    "    lp_links = lp_cloud['links']\n",
    "    lp_search = [l['href'] for l in lp_links if l['rel'] == 'search'][0]  # Define the search endpoint\n",
    "    lim = 100\n",
    "    search_query = f\"{lp_search}?&limit={lim}\"    # Add in a limit parameter to retrieve 100 items at a time.\n",
    "    bbox_num=[-104.79107047,   40.78311181, -104.67687336,   40.87008987]\n",
    "    bbox = f'{bbox_num[0]},{bbox_num[1]},{bbox_num[2]},{bbox_num[3]}'  # Defined from ROI bounds\n",
    "    search_query2 = f\"{search_query}&bbox={bbox}\"                                                  # Add bbox to query\n",
    "    date_time = hls_data['date_range'][0]+'/'+hls_data['date_range'][1]  # Define start time period / end time period\n",
    "    search_query3 = f\"{search_query2}&datetime={date_time}\"  # Add to query that already includes bbox\n",
    "    collections = r.get(search_query3).json()['features']    \n",
    "    hls_collections = [c for c in collections if 'HLS' in c['collection']]\n",
    "    s30_items = [h for h in hls_collections if h['collection'] == 'HLSS30.v1.5']  # Grab HLSS30 collection\n",
    "    l30_items = [h for h in hls_collections if h['collection'] == 'HLSL30.v1.5']  # Grab HLSL30 collection\n",
    "    \n",
    "    if aws:\n",
    "        for stac in s30_items:\n",
    "            for band in stac['assets']:\n",
    "                stac['assets'][band]['href'] = stac['assets'][band]['href'].replace('https://lpdaac.earthdata.nasa.gov/lp-prod-protected', \n",
    "                                                                                    '/vsis3/lp-prod-protected')\n",
    "        for stac in l30_items:\n",
    "            for band in stac['assets']:\n",
    "                stac['assets'][band]['href'] = stac['assets'][band]['href'].replace('https://lpdaac.earthdata.nasa.gov/lp-prod-protected', \n",
    "                                                                                    '/vsis3/lp-prod-protected')\n",
    "    return {'S30': s30_items,\n",
    "            'L30': l30_items}\n",
    "\n",
    "def setup_netrc(creds,aws):\n",
    "    urs = 'urs.earthdata.nasa.gov' \n",
    "    try:\n",
    "        netrcDir = os.path.expanduser(\"~/.netrc\")\n",
    "        netrc(netrcDir).authenticators(urs)[0]\n",
    "        del netrcDir\n",
    "\n",
    "    # Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\n",
    "    except FileNotFoundError:\n",
    "        homeDir = os.path.expanduser(\"~\")\n",
    "        Popen('touch {0}.netrc | chmod og-rw {0}.netrc | echo machine {1} >> {0}.netrc'.format(homeDir + os.sep, urs), shell=True)\n",
    "        Popen('echo login {} >> {}.netrc'.format(creds[0], homeDir + os.sep), shell=True)\n",
    "        Popen('echo password {} >> {}.netrc'.format(creds[1], homeDir + os.sep), shell=True)\n",
    "        del homeDir\n",
    "\n",
    "    # Determine OS and edit netrc file if it exists but is not set up for NASA Earthdata Login\n",
    "    except TypeError:\n",
    "        homeDir = os.path.expanduser(\"~\")\n",
    "        Popen('echo machine {1} >> {0}.netrc'.format(homeDir + os.sep, urs), shell=True)\n",
    "        Popen('echo login {} >> {}.netrc'.format(creds[0], homeDir + os.sep), shell=True)\n",
    "        Popen('echo password {} >> {}.netrc'.format(creds[1], homeDir + os.sep), shell=True)\n",
    "        del homeDir\n",
    "    del urs\n",
    "    if aws:\n",
    "        return(r.get('https://lpdaac.earthdata.nasa.gov/s3credentials').json())\n",
    "    else:\n",
    "        return('')\n",
    "\n",
    "def build_xr(stac_dict):\n",
    "    try:\n",
    "        s30_stack = stackstac.stack(stac_dict['S30'], epsg=32613, resolution=30, assets=[i for i in lut['HLSS30'] if lut['HLSS30'][i] in needed_bands])\n",
    "        s30_stack['band'] = [lut['HLSS30'][b] for b in s30_stack['band'].values]\n",
    "        s30_stack['time'] = [datetime.fromtimestamp(t) for t in s30_stack.time.astype('int').values//1000000000]\n",
    "        s30_stack = s30_stack.to_dataset(dim='band').reset_coords(['end_datetime', 'start_datetime'], drop=True)\n",
    "    except ValueError:\n",
    "        s30_stack = None\n",
    "    try:\n",
    "        l30_stack = stackstac.stack(stac_dict['L30'], epsg=32613, resolution=30, assets=[i for i in lut['HLSL30'] if lut['HLSL30'][i] in needed_bands])\n",
    "        l30_stack['band'] = [lut['HLSL30'][b] for b in l30_stack['band'].values]\n",
    "        l30_stack['time'] = [datetime.fromtimestamp(t) for t in l30_stack.time.astype('int').values//1000000000]\n",
    "        l30_stack = l30_stack.to_dataset(dim='band').reset_coords(['name', 'end_datetime', 'start_datetime'], drop=True)\n",
    "    except ValueError:\n",
    "        l30_stack = None\n",
    "    if s30_stack is not None and l30_stack is not None:\n",
    "        hls_stack = xr.concat([s30_stack, l30_stack], dim='time')\n",
    "    elif s30_stack is not None:\n",
    "        hls_stack = s30_stack\n",
    "    elif l30_stack is not None:\n",
    "        hls_stack = l30_stack\n",
    "    else:\n",
    "        print('No data found for date range')\n",
    "    return hls_stack.chunk({'time': 1, 'y': -1, 'x': -1})\n",
    "    \n",
    "def get_hls(creds, hls_data={}, aws=False):\n",
    "    #Seteup creds\n",
    "    \n",
    "    s3_cred = setup_netrc(creds,aws=aws)\n",
    "    #define gdalenv\n",
    "    if aws:\n",
    "        \n",
    "        env = dict(GDAL_DISABLE_READDIR_ON_OPEN='FALSE', \n",
    "                   #AWS_NO_SIGN_REQUEST='YES',\n",
    "                   GDAL_MAX_RAW_BLOCK_CACHE_SIZE='200000000',\n",
    "                   GDAL_SWATH_SIZE='200000000',\n",
    "                   VSI_CURL_CACHE_SIZE='200000000',\n",
    "                   CPL_VSIL_CURL_ALLOWED_EXTENSIONS='TIF',\n",
    "                   GDAL_HTTP_UNSAFESSL='YES',\n",
    "                   GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                   GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'),\n",
    "                   AWS_REGION='us-west-2',\n",
    "                   AWS_SECRET_ACCESS_KEY=s3_cred['secretAccessKey'],\n",
    "                   AWS_ACCESS_KEY_ID=s3_cred['accessKeyId'],\n",
    "                   AWS_SESSION_TOKEN=s3_cred['sessionToken'])\n",
    "    else:\n",
    "        env = dict(GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR', \n",
    "                   AWS_NO_SIGN_REQUEST='YES',\n",
    "                   GDAL_MAX_RAW_BLOCK_CACHE_SIZE='200000000',\n",
    "                   GDAL_SWATH_SIZE='200000000',\n",
    "                   VSI_CURL_CACHE_SIZE='200000000',\n",
    "                   GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                   GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "\n",
    "\n",
    "    os.environ.update(env)\n",
    "    \n",
    "    catalog = NASA_CMR_STAC(hls_data, aws)\n",
    "    da  = build_xr(catalog)\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1028'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"c3cbc486-de47-4eba-b738-493f539df84d\" data-root-id=\"1028\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"3ca3dc0b-0e2b-448f-99db-dc24d5d4935a\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"enabled_dates\":[\"2000-01-01\",\"2000-01-02\"],\"margin\":[5,10,5,10],\"title\":\"Calendar\",\"value\":\"2000-01-01\"},\"id\":\"1035\",\"type\":\"DatePicker\"},{\"attributes\":{\"child\":{\"id\":\"1044\"},\"name\":\"Biomass\",\"title\":\"Biomass\"},\"id\":\"1046\",\"type\":\"Panel\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Cover\"},\"id\":\"1042\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"end\":2000,\"format\":{\"id\":\"1027\"},\"margin\":[5,10,5,10],\"start\":200,\"step\":25,\"title\":\"Threshold\",\"value\":500},\"id\":\"1036\",\"type\":\"Slider\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Biomass\"},\"id\":\"1045\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"children\":[{\"id\":\"1029\"},{\"id\":\"1034\"},{\"id\":\"1039\"}],\"margin\":[0,0,0,0],\"name\":\"Column01644\",\"sizing_mode\":\"stretch_both\"},\"id\":\"1028\",\"type\":\"Column\"},{\"attributes\":{\"children\":[{\"id\":\"1038\"}],\"margin\":[0,0,0,0],\"name\":\"Row01617\"},\"id\":\"1037\",\"type\":\"Row\"},{\"attributes\":{\"margin\":[5,10,5,10],\"max_length\":5000,\"placeholder\":\"Enter Username...\",\"title\":\"NASA Earthdata Login\"},\"id\":\"1030\",\"type\":\"PasswordInput\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Biomass threshold\"},\"id\":\"1048\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"children\":[{\"id\":\"1035\"},{\"id\":\"1036\"},{\"id\":\"1037\"}],\"margin\":[0,0,0,0],\"name\":\"Column01620\",\"sizing_mode\":\"stretch_both\"},\"id\":\"1034\",\"type\":\"Column\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"ParamMethod01613\",\"text\":\"&lt;p&gt;Not yet launched&lt;/p&gt;\"},\"id\":\"1038\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"margin\":[5,10,5,10],\"max_length\":5000,\"placeholder\":\"Enter Password...\"},\"id\":\"1031\",\"type\":\"PasswordInput\"},{\"attributes\":{\"children\":[{\"id\":\"1042\"}],\"margin\":[0,0,0,0],\"name\":\"Cover\"},\"id\":\"1041\",\"type\":\"Row\"},{\"attributes\":{\"children\":[{\"id\":\"1030\"},{\"id\":\"1031\"},{\"id\":\"1032\"},{\"id\":\"1033\"}],\"css_classes\":[\"panel-widget-box\"],\"margin\":[0,0,0,0],\"name\":\"Download Options\",\"sizing_mode\":\"stretch_both\"},\"id\":\"1029\",\"type\":\"Column\"},{\"attributes\":{\"format\":\"%d kg/ha\"},\"id\":\"1027\",\"type\":\"PrintfTickFormatter\"},{\"attributes\":{\"end\":1619476851000.0,\"margin\":[5,10,5,10],\"start\":1546300800000.0,\"value\":[1546300800000.0,1619476851000.0]},\"id\":\"1032\",\"type\":\"DateRangeSlider\"},{\"attributes\":{\"children\":[{\"id\":\"1048\"}],\"margin\":[0,0,0,0],\"name\":\"Biomass threshold\"},\"id\":\"1047\",\"type\":\"Row\"},{\"attributes\":{\"margin\":[0,0,0,0],\"sizing_mode\":\"stretch_both\",\"tabs\":[{\"id\":\"1043\"},{\"id\":\"1046\"},{\"id\":\"1049\"}]},\"id\":\"1040\",\"type\":\"Tabs\"},{\"attributes\":{\"children\":[{\"id\":\"1045\"}],\"margin\":[0,0,0,0],\"name\":\"Biomass\"},\"id\":\"1044\",\"type\":\"Row\"},{\"attributes\":{\"child\":{\"id\":\"1047\"},\"name\":\"Biomass threshold\",\"title\":\"Biomass threshold\"},\"id\":\"1049\",\"type\":\"Panel\"},{\"attributes\":{\"children\":[{\"id\":\"1040\"}],\"margin\":[0,0,0,0],\"name\":\"Column01643\",\"sizing_mode\":\"stretch_both\"},\"id\":\"1039\",\"type\":\"Column\"},{\"attributes\":{\"child\":{\"id\":\"1041\"},\"name\":\"Cover\",\"title\":\"Cover\"},\"id\":\"1043\",\"type\":\"Panel\"},{\"attributes\":{\"icon\":null,\"label\":\"Load Data and Run Analysis\",\"margin\":[5,10,5,10],\"subscribed_events\":[\"button_click\"]},\"id\":\"1033\",\"type\":\"Button\"},{\"attributes\":{\"client_comm_id\":\"1f9d8f555cfe4bbe9d13402e31abeeed\",\"comm_id\":\"97e3713a2f5c480f911d5a7be2da3941\",\"plot_id\":\"1028\"},\"id\":\"1050\",\"type\":\"panel.models.comm_manager.CommManager\"}],\"root_ids\":[\"1028\",\"1050\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.1\"}};\n",
       "    var render_items = [{\"docid\":\"3ca3dc0b-0e2b-448f-99db-dc24d5d4935a\",\"root_ids\":[\"1028\"],\"roots\":{\"1028\":\"c3cbc486-de47-4eba-b738-493f539df84d\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Column(sizing_mode='stretch_both')\n",
       "    [0] Column(css_classes=['panel-widget-box'], name='Download Options', sizing_mode='stretch_both')\n",
       "        [0] PasswordInput(name='NASA Earthdata Login', placeholder='Enter Username...')\n",
       "        [1] PasswordInput(placeholder='Enter Password...')\n",
       "        [2] DateRangeSlider(end=datetime.datetime(2021, ..., start=datetime.datetime(2019, ..., value=(datetime.datetime(2019, ...)\n",
       "        [3] Button(name='Load Data and R...)\n",
       "    [1] Column(sizing_mode='stretch_both')\n",
       "        [0] DatePicker(enabled_dates=[datetime.date(2000, ...], name='Calendar', value=datetime.date(2000, 1, 1))\n",
       "        [1] IntSlider(end=2000, format=PrintfTickFormatter(id='10..., name='Threshold', start=200, step=25, value=500)\n",
       "        [2] ParamMethod(method)\n",
       "    [2] Column(sizing_mode='stretch_both')\n",
       "        [0] Tabs(sizing_mode='stretch_both')\n",
       "            [0] ParamMethod(method, name='Cover')\n",
       "            [1] ParamMethod(method, name='Biomass')\n",
       "            [2] ParamMethod(method, name='Biomass threshold')"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1028"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HLS_BM_Explorer(pm.Parameterized):\n",
    "    action = pm.Action(lambda x: x.param.trigger('action'), label='Load Data and Run Analysis')\n",
    "    username_input = pn.widgets.PasswordInput(name='NASA Earthdata Login', placeholder='Enter Username...')\n",
    "    password_input = pn.widgets.PasswordInput(name='', placeholder='Enter Password...')\n",
    "    date_picker = pn.widgets.DatePicker(name='Calendar',\n",
    "                                        value=datetime(2000,1,1).date(),\n",
    "                                        enabled_dates = [datetime(2000,1,1).date(),datetime(2000,1,2).date()])\n",
    "    d_range = pn.widgets.DateRangeSlider(name='',end=d_bounds[-1],start=d_bounds[0])\n",
    "    thresh_picker = pn.widgets.IntSlider(name='Threshold', start=200, end=2000, step=25, value=500,\n",
    "                                     format=PrintfTickFormatter(format='%d kg/ha'))\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(HLS_BM_Explorer, self).__init__(**params)\n",
    "        self.data = ''\n",
    "        self.da = ''\n",
    "        self.da_cov = ''\n",
    "        self.da_cov_sel = ''\n",
    "        self.da_bm = ''\n",
    "        self.da_bm_sel = ''\n",
    "        self.da_se = ''\n",
    "        self.da_se_sel = ''\n",
    "    \n",
    "    @pm.depends('action')\n",
    "    def access_data(self):\n",
    "        message = 'Not yet launched'\n",
    "        if self.username_input.value != '':\n",
    "            try:\n",
    "                message = 'button clicked'\n",
    "                d_from = str(self.d_range.value[0].date())\n",
    "                d_to = str(self.d_range.value[1].date())\n",
    "                tmp_data = get_hls([self.username_input.value,self.password_input.value],\n",
    "                                       hls_data={'date_range':[d_from,d_to]},aws=True)\n",
    "                message = 'data querried'\n",
    "                #os.environ.update(env)\n",
    "                with LocalCluster(threads_per_worker=1) as cluster, Client(cluster) as cl:\n",
    "                    bbox_num=[-104.79107047,   40.78311181, -104.67687336,   40.87008987]\n",
    "                    utmProj = Proj(\"+proj=utm +zone=13U, +north +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\n",
    "                    bbox_utm = utmProj([bbox_num[i] for i in [0, 2]], [bbox_num[i] for i in [3, 1]])\n",
    "                    self.data = tmp_data.loc[dict(x=slice(*tuple(bbox_utm[0])), y=slice(*tuple(bbox_utm[1])))]\n",
    "\n",
    "                message = 'data loaded'\n",
    "                self.date_picker.enabled_dates = [datetime.utcfromtimestamp(x).date() for\n",
    "                                                  x in self.data.time.data.astype('int') * 1e-9]\n",
    "                self.date_picker.value = datetime.utcfromtimestamp(self.data.time[-1].data.astype('int') * 1e-9).date()\n",
    "                message = 'date picker set'\n",
    "                da = self.data\n",
    "                da['time'] = da.time.dt.floor(\"D\")\n",
    "                da = da.rename(dict(time='date'))\n",
    "                da_mask = mask_hls(da['FMASK'])\n",
    "                da = da.where(da_mask == 0)\n",
    "                message = 'data masked'\n",
    "                #da = da.groupby('date').mean()\n",
    "                message = 'data averaged'\n",
    "                self.da = da\n",
    "                message = 'data reset'\n",
    "                bm_mod = pickle.load(open('src/models/CPER_HLS_to_VOR_biomass_model_lr_simp.pk', 'rb'))\n",
    "                da_bm = pred_bm(da, bm_mod)\n",
    "                da_bm = da_bm.where(da_bm > 0)\n",
    "                da_se = pred_bm_se(da, bm_mod)\n",
    "                da_se = da_se.where(da_bm > 0)\n",
    "                self.da_bm = da_bm\n",
    "                self.da_se = da_se\n",
    "                self.bm_mod = bm_mod\n",
    "                message = 'bm calculated'\n",
    "\n",
    "                cov_mod = pickle.load(open('src/models/CPER_HLS_to_LPI_cover_pls_binned_model.pk', 'rb'))\n",
    "                da_cov = pred_cov(da, cov_mod)\n",
    "                message = 'cover calculated'\n",
    "                da_cov = da_cov[['SD', 'GREEN', 'BARE']].to_array(dim='type')\n",
    "                message = 'cover converted'\n",
    "                da_cov = da_cov.where((da_cov < 1.0) | (da_cov.isnull()), 1.0)\n",
    "                da_cov = da_cov.where(~(da_cov.any(dim='date').isnull()))\n",
    "                message = 'cover masked'\n",
    "                da_cov = da_cov * 255 \n",
    "                da_cov = da_cov.astype('uint8')\n",
    "                message = 'conver integered'\n",
    "                self.da_cov = da_cov\n",
    "                message = 'cover loaded'\n",
    "                message = 'Success!'\n",
    "                return message\n",
    "            except:\n",
    "                return message + ': App Failure'\n",
    "        else:\n",
    "            return message\n",
    "        \n",
    "    \n",
    "    @pm.depends('date_picker.param')\n",
    "    def load_cov(self):\n",
    "        if self.da_cov is not '':\n",
    "            self.da_cov_sel = self.da_cov.sel(date=np.datetime64(self.date_picker.value))\n",
    "            cov_map = self.da_cov_sel.hvplot.rgb(x='x',y='y', \n",
    "                                                                                            bands='type', \n",
    "                                                                                            tiles='EsriImagery', \n",
    "                                                                                            crs=ccrs.UTM(13),\n",
    "                                                                                             data_aspect=0.6).opts(responsive=True,\n",
    "                                                                                                                xticks=None,\n",
    "                                                                                                                yticks=None)\n",
    "            return cov_map\n",
    "        else:\n",
    "            return('')\n",
    "    \n",
    "    @pm.depends('date_picker.param')\n",
    "    def load_bm(self):\n",
    "        if self.da_bm is not '':\n",
    "            bm_map = self.da_bm.sel(date=np.datetime64(self.date_picker.value)).hvplot(x='x',y='y',\n",
    "                                                                                       tiles='EsriImagery',\n",
    "                                                                                       crs=ccrs.UTM(13),\n",
    "                                                                                       cmap='inferno', \n",
    "                                                                                       clim=(100, 1000), \n",
    "                                                                                       colorbar=False,\n",
    "                                                                                       data_aspect=0.6).opts(responsive=True,\n",
    "                                                                                                                xticks=None,\n",
    "                                                                                                                yticks=None)\n",
    "            return bm_map\n",
    "        else:\n",
    "            return('')\n",
    "    \n",
    "    @pm.depends('date_picker.param', 'thresh_picker.param')\n",
    "    def load_thresh(self):\n",
    "        if self.da_bm is not '':\n",
    "            da_thresh = pred_bm_thresh(self.da_bm, self.da_se, self.thresh_picker.value)      \n",
    "            thresh_map = da_thresh.sel(date=np.datetime64(self.date_picker.value)).hvplot(x='x', y='y', \n",
    "                                                                                          tiles='EsriImagery', \n",
    "                                                                                          crs=ccrs.UTM(13),\n",
    "                                                                                          cmap='YlOrRd', \n",
    "                                                                                          clim=(0.05, 0.95),\n",
    "                                                                                          colorbar=False,\n",
    "                                                                                          data_aspect=0.6).opts(responsive=True,\n",
    "                                                                                                                xticks=None,\n",
    "                                                                                                                yticks=None)\n",
    "            return thresh_map\n",
    "        else:\n",
    "            return('')\n",
    "        \n",
    "    @pm.depends('access_data')\n",
    "    def showdata(self):\n",
    "        return(pn.pane.HTML(self.data,sizing_mode='stretch_both',max_width=250))\n",
    "    \n",
    "    @pm.depends('thresh_picker.param')\n",
    "    def showthresh(self):\n",
    "        return(pn.pane.HTML(str(self.thresh_picker.value),sizing_mode='stretch_both',max_width=250))\n",
    "    \n",
    "app = HLS_BM_Explorer(name='Central Plains Experimental Range: HLS Biomass')\n",
    "\n",
    "app_layout = pn.Column(pn.Column(app.username_input,\n",
    "                                        app.password_input,\n",
    "                                        app.d_range,\n",
    "                                        pn.panel(app.param.action),\n",
    "                                        sizing_mode='stretch_both',\n",
    "                                        name=\"Download Options\",\n",
    "                                        css_classes=['panel-widget-box']),\n",
    "                       pn.Column(app.date_picker, \n",
    "                                 app.thresh_picker,\n",
    "                                 app.access_data,\n",
    "                                 sizing_mode='stretch_both'),\n",
    "                       pn.Column(pn.Tabs(('Cover', app.load_cov),\n",
    "                                         ('Biomass', app.load_bm),\n",
    "                                         ('Biomass threshold', app.load_thresh), sizing_mode='stretch_both'),\n",
    "                                 sizing_mode='stretch_both'), sizing_mode='stretch_both')\n",
    "#template_theme.show(port=9000)\n",
    "app_layout.servable()\n",
    "#pn.serve(app_layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

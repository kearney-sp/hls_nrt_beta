{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, concurrent.futures, time, warnings, os, re, pickle\n",
    "from osgeo import gdal\n",
    "import requests as r\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "import param as pm\n",
    "import pandas as pd\n",
    "from collections import OrderedDict as odict\n",
    "import numpy as np\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse,fromstring\n",
    "from affine import Affine\n",
    "from pandas import to_datetime\n",
    "import jinja2 as jj2\n",
    "from rasterio.crs import CRS\n",
    "from tempfile import NamedTemporaryFile\n",
    "from datetime import datetime\n",
    "from netrc import netrc\n",
    "from subprocess import Popen\n",
    "from pyproj import Proj\n",
    "from src.hls_funcs.masks import mask_hls\n",
    "from src.hls_funcs.predict import pred_cov, pred_bm, pred_bm_se, pred_bm_thresh\n",
    "import cartopy.crs as ccrs\n",
    "from bokeh.models.formatters import PrintfTickFormatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/opt/conda/envs/py_geo/bin/pip3 install pysptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LUT dict including the HLS product bands mapped to names\n",
    "lut = {'HLSS30': \n",
    "       {'COASTAL-AEROSOL':'B01', 'BLUE':'B02', 'GREEN':'B03', 'RED':'B04', \n",
    "        'RED-EDGE1':'B05', 'RED-EDGE2':'B06', 'RED-EDGE3':'B07', 'NIR-Broad':'B08', 'NIR1':'B8A', \n",
    "        'WATER-VAPOR':'B09', 'CIRRUS':'B10', 'SWIR1':'B11', 'SWIR2':'B12', 'FMASK':'Fmask'},\n",
    "       'HLSL30': \n",
    "       {'COASTAL-AEROSOL':'B01', 'BLUE':'B02', 'GREEN':'B03', 'RED':'B04', \n",
    "        'NIR1':'B05', 'SWIR1':'B06','SWIR2':'B07', \n",
    "        'CIRRUS':'B09', 'TIR1':'B10', 'TIR2':'B11', 'FMASK':'Fmask'}}\n",
    "\n",
    "# List of all available/acceptable band names\n",
    "all_bands = ['ALL', 'COASTAL-AEROSOL', 'BLUE', 'GREEN', 'RED', 'RED-EDGE1', 'RED-EDGE2', 'RED-EDGE3', \n",
    "             'NIR1', 'SWIR1', 'SWIR2', 'CIRRUS', 'TIR1', 'TIR2', 'WATER-VAPOR', 'FMASK']\n",
    "\n",
    "d_bounds = (datetime(2019, 1, 1), datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_hls_meta(stac_id):\n",
    "    var_url = urlopen('https://cmr.earthdata.nasa.gov/search/concepts/'+stac_id)\n",
    "    xmldoc = parse(var_url)\n",
    "    res={stac_id:{}}\n",
    "    for child in xmldoc.findall('.//AdditionalAttributes/AdditionalAttribute'):\n",
    "        if child.find('Name').text in ['ULX',\n",
    "                                       'ULY',\n",
    "                                       'NROWS',\n",
    "                                       'NCOLS',\n",
    "                                       'SPATIAL_RESOLUTION',\n",
    "                                       'HORIZONTAL_CS_CODE',\n",
    "                                       'SENSING_TIME',\n",
    "                                       'MGRS_TILE_ID',\n",
    "                                       'CLOUD_COVERAGE',\n",
    "                                       'FILLVALUE',\n",
    "                                       'QA_FILLVALUE',\n",
    "                                       'MEAN_SUN_AZIMUTH_ANGLE',\n",
    "                                       'MEAN_SUN_ZENITH_ANGLE',\n",
    "                                       'MEAN_VIEW_AZIMUTH_ANGLE',\n",
    "                                       'MEAN_VIEW_ZENITH_ANGLE',\n",
    "                                       'NBAR_SOLAR_ZENITH',\n",
    "                                       'IDENTIFIER_PRODUCT_DOI',\n",
    "                                       'IDENTIFIER_PRODUCT_DOI_AUTHORITY',\n",
    "                                       'REF_SCALE_FACTOR',\n",
    "                                       'ADD_OFFSET']:\n",
    "            res[stac_id][child.find('Name').text]=child.find('.//Value').text\n",
    "    return(res)\n",
    "\n",
    "def build_xr(catalog,bands,is_aws):\n",
    "    #Retreive Metadata using threads - not cpu bound, so works well\n",
    "    l_meta={}\n",
    "    with concurrent.futures.ThreadPoolExecutor(5) as executor:\n",
    "        futures = []\n",
    "        for stac in catalog:\n",
    "            stac_id = stac['id']\n",
    "            futures.append(executor.submit(open_hls_meta, stac_id=stac_id))\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            l_meta.update(future.result())\n",
    "        for stac in catalog:\n",
    "            stac_id = stac['id']\n",
    "            for band in bands:\n",
    "                if bool(re.search('S30', l_meta[stac_id]['IDENTIFIER_PRODUCT_DOI'])):\n",
    "                        b = lut['HLSS30'][band]\n",
    "                elif bool(re.search('L30', l_meta[stac_id]['IDENTIFIER_PRODUCT_DOI'])):\n",
    "                        b = lut['HLSL30'][band]\n",
    "                if is_aws:\n",
    "                    l_meta[stac_id][b+'_url'] = stac['assets'][b]['href'].replace('https://lpdaac.earthdata.nasa.gov/lp-prod-protected', '/vsis3/lp-prod-protected')\n",
    "                else:\n",
    "                    l_meta[stac_id][b+'_url'] = '/vsicurl/'+stac['assets'][b]['href']#.replace('https://lpdaac.earthdata.nasa.gov/lp-prod-protected', '/vsis3/lp-prod-protected')\n",
    "    \n",
    "    #Setup template file for each raster. Use Jinja to quickly fill in metadata.\n",
    "    vrt_template = jj2.Template('''\n",
    "    <VRTDataset rasterXSize=\"{{rasterXSize}}\" rasterYSize=\"{{rasterYSize}}\">\n",
    "      <SRS>{{SRS}}</SRS>\n",
    "      <GeoTransform>{{GeoTransform}}</GeoTransform>\n",
    "      <VRTRasterBand dataType=\"{{dtype}}\" band=\"1\">\n",
    "        <NoDataValue>{{nodata}}</NoDataValue>\n",
    "        <Scale>{{scale}}</Scale>\n",
    "        <Metadata>\n",
    "          <MDI key=\"obs_date\">{{obs_date}}</MDI>\n",
    "        </Metadata>\n",
    "        <SimpleSource>\n",
    "          <SourceFilename relativeToVRT=\"1\">{{SourceFilename}}</SourceFilename>\n",
    "          <SourceBand>1</SourceBand>\n",
    "          <SourceProperties RasterXSize=\"{{rasterXSize}}\" RasterYSize=\"{{rasterYSize}}\" DataType=\"{{dtype}}\" BlockXSize=\"1024\" BlockYSize=\"1024\" />\n",
    "          <SrcRect xOff=\"0\" yOff=\"0\" xSize=\"{{rasterXSize}}\" ySize=\"{{rasterYSize}}\" />\n",
    "          <DstRect xOff=\"0\" yOff=\"0\" xSize=\"{{rasterXSize}}\" ySize=\"{{rasterYSize}}\" />\n",
    "          <NODATA>{{nodata}}</NODATA>\n",
    "        </SimpleSource>\n",
    "      </VRTRasterBand>\n",
    "    </VRTDataset>\n",
    "    ''')\n",
    "    \n",
    "    #Enumerate the stac catalog (by band) and create vrt objects in a dictionary (l_vrt)\n",
    "    l_vrt={}\n",
    "    for i, band in enumerate(bands):             \n",
    "        l_tmp = []\n",
    "        for k in l_meta.keys():\n",
    "            item = l_meta[k]\n",
    "            if bool(re.search('S30', item['IDENTIFIER_PRODUCT_DOI'])):\n",
    "                b = lut['HLSS30'][band]\n",
    "            elif bool(re.search('L30', item['IDENTIFIER_PRODUCT_DOI'])):\n",
    "                b = lut['HLSL30'][band]  \n",
    "            vrt = vrt_template.render(rasterXSize = int(item['NCOLS']),\n",
    "                                      rasterYSize = int(item['NROWS']),\n",
    "                                      SourceFilename = item[b+'_url'],\n",
    "                                      SRS=CRS.from_epsg('32613').wkt,#CRS.from_epsg(item['HORIZONTAL_CS_CODE'].split(':')[1]).wkt,\n",
    "                                      GeoTransform=item['ULX']+', '+item['SPATIAL_RESOLUTION']+', 0, '+item['ULY']+', 0, -'+item['SPATIAL_RESOLUTION'],\n",
    "                                      band=band,\n",
    "                                      obs_date=item['SENSING_TIME'],\n",
    "                                      dtype='int16',\n",
    "                                      nodata=item['FILLVALUE'],\n",
    "                                      scale=item['REF_SCALE_FACTOR'])\n",
    "            l_tmp.append(vrt)\n",
    "        l_vrt[band] = l_tmp\n",
    "    \n",
    "    #Use GDAL to merge vrts from the same bands\n",
    "    vrt_files={}\n",
    "    for b in bands:\n",
    "        with NamedTemporaryFile() as tmpfile:\n",
    "            vrt_options = gdal.BuildVRTOptions(separate=True, bandList=[1])\n",
    "            my_vrt = gdal.BuildVRT(tmpfile.name, l_vrt[b], options=vrt_options)\n",
    "            my_vrt = None\n",
    "            f = tmpfile.read().decode(\"utf-8\")\n",
    "            vrt_files[b]=f\n",
    "    \n",
    "    #Extract metadata and lazy-load a nd merge into single xarray object\n",
    "    if type(bands) == str:\n",
    "        bands = [bands]\n",
    "    b_l = []\n",
    "    for b in bands:\n",
    "        v = vrt_files[b]\n",
    "        xmldoc = fromstring(v)\n",
    "        dates = []\n",
    "        for child in xmldoc.findall('''.//VRTRasterBand/ComplexSource/SourceFilename'''):\n",
    "            dates.append(to_datetime(child.text[child.text.find('obs_date')+10:\n",
    "                                                child.text.find('obs_date')+36]).date())\n",
    "        ds_tmp = xr.open_rasterio(v,chunks={'band':1,\n",
    "                                            'x':'auto',\n",
    "                                            'y':'auto'}).to_dataset(name=b)\n",
    "        ds_tmp = ds_tmp.rename({'band':'time'})\n",
    "        ds_tmp['time'] = to_datetime(dates)\n",
    "        b_l.append(ds_tmp)\n",
    "    \n",
    "    ds = xr.merge(b_l)\n",
    "    return(ds,vrt_files)\n",
    "\n",
    "\n",
    "def NASA_CMR_STAC(hls_data):\n",
    "    stac = 'https://cmr.earthdata.nasa.gov/stac/' # CMR-STAC API Endpoint\n",
    "    stac_response = r.get(stac).json()            # Call the STAC API endpoint\n",
    "    stac_lp = [s for s in stac_response['links'] if 'LP' in s['title']]  # Search for only LP-specific catalogs\n",
    "\n",
    "    # LPCLOUD is the STAC catalog we will be using and exploring today\n",
    "    lp_cloud = r.get([s for s in stac_lp if s['title'] == 'LPCLOUD'][0]['href']).json()\n",
    "    lp_links = lp_cloud['links']\n",
    "    lp_collections = [l['href'] for l in lp_links if l['rel'] == 'collections'][0]  # Set collections endpoint to variable\n",
    "    lp_search = [l['href'] for l in lp_links if l['rel'] == 'search'][0]  # Define the search endpoint\n",
    "    lim = 100\n",
    "    search_query = f\"{lp_search}?&limit={lim}\"    # Add in a limit parameter to retrieve 100 items at a time.\n",
    "    bbox_num=[-104.79107047,   40.78311181, -104.67687336,   40.87008987]\n",
    "    bbox = f'{bbox_num[0]},{bbox_num[1]},{bbox_num[2]},{bbox_num[3]}'  # Defined from ROI bounds\n",
    "    search_query2 = f\"{search_query}&bbox={bbox}\"                                                  # Add bbox to query\n",
    "    date_time = hls_data['date_range'][0]+'/'+hls_data['date_range'][1]  # Define start time period / end time period\n",
    "    search_query3 = f\"{search_query2}&datetime={date_time}\"  # Add to query that already includes bbox\n",
    "    collections = r.get(search_query3).json()['features']    \n",
    "    hls_collections = [c for c in collections if 'HLS' in c['collection']]\n",
    "    s30_items = [h for h in hls_collections if h['collection'] == 'HLSS30.v1.5']  # Grab HLSS30 collection\n",
    "    l30_items = [h for h in hls_collections if h['collection'] == 'HLSL30.v1.5']  # Grab HLSL30 collection\n",
    "    \n",
    "    # Combine the S30 ad L30 items:\n",
    "    return(s30_items + l30_items)\n",
    "\n",
    "def setup_netrc(creds,aws):\n",
    "    urs = 'urs.earthdata.nasa.gov' \n",
    "    try:\n",
    "        netrcDir = os.path.expanduser(\"~/.netrc\")\n",
    "        netrc(netrcDir).authenticators(urs)[0]\n",
    "        del netrcDir\n",
    "\n",
    "    # Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\n",
    "    except FileNotFoundError:\n",
    "        homeDir = os.path.expanduser(\"~\")\n",
    "        Popen('touch {0}.netrc | chmod og-rw {0}.netrc | echo machine {1} >> {0}.netrc'.format(homeDir + os.sep, urs), shell=True)\n",
    "        Popen('echo login {} >> {}.netrc'.format(creds[0], homeDir + os.sep), shell=True)\n",
    "        Popen('echo password {} >> {}.netrc'.format(creds[1], homeDir + os.sep), shell=True)\n",
    "        del homeDir\n",
    "\n",
    "    # Determine OS and edit netrc file if it exists but is not set up for NASA Earthdata Login\n",
    "    except TypeError:\n",
    "        homeDir = os.path.expanduser(\"~\")\n",
    "        Popen('echo machine {1} >> {0}.netrc'.format(homeDir + os.sep, urs), shell=True)\n",
    "        Popen('echo login {} >> {}.netrc'.format(creds[0], homeDir + os.sep), shell=True)\n",
    "        Popen('echo password {} >> {}.netrc'.format(creds[1], homeDir + os.sep), shell=True)\n",
    "        del homeDir\n",
    "    del urs\n",
    "    if aws:\n",
    "        return(r.get('https://lpdaac.earthdata.nasa.gov/s3credentials').json())\n",
    "    else:\n",
    "        return('')\n",
    "\n",
    "def get_hls(creds,hls_data={},aws=True):\n",
    "    #Seteup creds\n",
    "    \n",
    "    s3_cred = setup_netrc(creds,aws=aws)\n",
    "    #define gdalenv\n",
    "    if aws:\n",
    "        \n",
    "        env = dict(GDAL_DISABLE_READDIR_ON_OPEN='YES', \n",
    "                   #AWS_NO_SIGN_REQUEST='YES',\n",
    "                   GDAL_MAX_RAW_BLOCK_CACHE_SIZE='200000000',\n",
    "                   GDAL_SWATH_SIZE='200000000',\n",
    "                   VSI_CURL_CACHE_SIZE='200000000',\n",
    "                   CPL_VSIL_CURL_ALLOWED_EXTENSIONS='TIF',\n",
    "                   GDAL_HTTP_UNSAFESSL='YES',\n",
    "                   GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                   GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'),\n",
    "                   AWS_REGION='us-west-2',\n",
    "                   AWS_SECRET_ACCESS_KEY=s3_cred['secretAccessKey'],\n",
    "                   AWS_ACCESS_KEY_ID=s3_cred['accessKeyId'],\n",
    "                   AWS_SESSION_TOKEN=s3_cred['sessionToken'])\n",
    "    else:\n",
    "        env = dict(GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR', \n",
    "                   AWS_NO_SIGN_REQUEST='YES',\n",
    "                   GDAL_MAX_RAW_BLOCK_CACHE_SIZE='200000000',\n",
    "                   GDAL_SWATH_SIZE='200000000',\n",
    "                   VSI_CURL_CACHE_SIZE='200000000',\n",
    "                   GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                   GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "\n",
    "\n",
    "    os.environ.update(env)\n",
    "    \n",
    "    catalog = NASA_CMR_STAC(hls_data)\n",
    "    da,vrt  = build_xr(catalog,  ['BLUE', 'GREEN', 'RED', 'NIR1', 'SWIR1', 'SWIR2', 'FMASK'],aws)\n",
    "    return(da,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HLS_BM_Explorer(pm.Parameterized):\n",
    "    action = pm.Action(lambda x: x.param.trigger('action'), label='Load Data and Run Analysis')\n",
    "    username_input = pn.widgets.PasswordInput(name='NASA Earthdata Login', placeholder='Enter Username...')\n",
    "    password_input = pn.widgets.PasswordInput(name='', placeholder='Enter Password...')\n",
    "    date_picker = pn.widgets.DatePicker(name='Calendar',\n",
    "                                        value=datetime(2000,1,1).date(),\n",
    "                                        enabled_dates = [datetime(2000,1,1).date(),datetime(2000,1,2).date()])\n",
    "    d_range = pn.widgets.DateRangeSlider(name='',end=d_bounds[-1],start=d_bounds[0])\n",
    "    thresh_picker = pn.widgets.IntSlider(name='Threshold', start=200, end=2000, step=25, value=500,\n",
    "                                     format=PrintfTickFormatter(format='%d kg/ha'))\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(HLS_BM_Explorer, self).__init__(**params)\n",
    "        self.data = ''\n",
    "        self.da = ''\n",
    "        self.da_cov = ''\n",
    "        self.da_bm = ''\n",
    "        self.da_se = ''\n",
    "        self.bm_mod = ''\n",
    "    \n",
    "    @pm.depends('action', watch=True)\n",
    "    def access_data(self):\n",
    "        if self.username_input.value != '':\n",
    "            try:\n",
    "                d_from = str(self.d_range.value[0].date())\n",
    "                d_to = str(self.d_range.value[1].date())\n",
    "                tmp_data, env = get_hls([self.username_input.value,self.password_input.value],\n",
    "                                       hls_data={'date_range':[d_from,d_to]},aws=True)\n",
    "                os.environ.update(env)\n",
    "                with LocalCluster(threads_per_worker=1) as cluster, Client(cluster) as cl:\n",
    "                    bbox_num=[-104.79107047,   40.78311181, -104.67687336,   40.87008987]\n",
    "                    utmProj = Proj(\"+proj=utm +zone=13U, +north +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\n",
    "                    bbox_utm = utmProj([bbox_num[i] for i in [0, 2]], [bbox_num[i] for i in [3, 1]])\n",
    "                    self.data = tmp_data.loc[dict(x=slice(*tuple(bbox_utm[0])), y=slice(*tuple(bbox_utm[1])))]\n",
    "\n",
    "                self.date_picker.enabled_dates = [datetime.utcfromtimestamp(x).date() for\n",
    "                                                  x in self.data.time.data.astype('int') * 1e-9]\n",
    "                self.date_picker.value = datetime.utcfromtimestamp(self.data.time[-1].data.astype('int') * 1e-9).date()\n",
    "\n",
    "                da = self.data\n",
    "                da_mask = mask_hls(da['FMASK'])\n",
    "                da = da.where(da_mask == 0)\n",
    "                da = da.groupby('time').mean()\n",
    "                self.da = da\n",
    "\n",
    "                bm_mod = pickle.load(open('src/models/CPER_HLS_to_VOR_biomass_model_lr_simp.pk', 'rb'))\n",
    "                da_bm = pred_bm(da, bm_mod)\n",
    "                da_bm = da_bm.where(da_bm > 0)\n",
    "                da_se = pred_bm_se(da, bm_mod)\n",
    "                da_se = da_se.where(da_bm > 0)\n",
    "                self.da_bm = da_bm\n",
    "                self.da_se = da_se\n",
    "                self.bm_mod = bm_mod\n",
    "                \n",
    "                ends_dict = {\n",
    "                    'SD': {\n",
    "                        'ndvi': 0.30,\n",
    "                        'dfi': 16,\n",
    "                        'bai_126': 155},\n",
    "                    'GREEN': {\n",
    "                        'ndvi': 0.55,\n",
    "                        'dfi': 10,\n",
    "                        'bai_126': 160},\n",
    "                    'BARE': {\n",
    "                        'ndvi': 0.10,\n",
    "                        'dfi': 8,\n",
    "                        'bai_126': 140}}\n",
    "                da_cov = pred_cov(da, ends_dict)\n",
    "                da_cov = da_cov.to_array(dim='type')\n",
    "                da_cov = da_cov.where((da_cov < 1.0) | (da_cov.isnull()), 1.0)\n",
    "                da_cov = da_cov.where(~(da_cov.any(dim='time').isnull()))\n",
    "                self.da_cov = da_cov\n",
    "                return('Success!')\n",
    "            except:\n",
    "                return('App Failure')\n",
    "        else:\n",
    "            return('Not Yet Launched')\n",
    "        \n",
    "    \n",
    "    @pm.depends('date_picker.param')\n",
    "    def load_cov(self):\n",
    "        if self.da_cov is not '':\n",
    "            cov_map = self.da_cov.sel(time=np.datetime64(self.date_picker.value)).hvplot.rgb(x='x',y='y', \n",
    "                                                                                            bands='type', \n",
    "                                                                                            tiles='EsriImagery', \n",
    "                                                                                            crs=ccrs.UTM(13),\n",
    "                                                                                            sizing_mode='stretch_both',\n",
    "                                                                                            width=350,\n",
    "                                                                                            title='CV: '+str(self.date_picker.value))#.opts(height=int(500*1.5), width=int(750*1.5))\n",
    "            return cov_map\n",
    "        else:\n",
    "            return('')\n",
    "    \n",
    "    @pm.depends('date_picker.param')\n",
    "    def load_bm(self):\n",
    "        if self.da_bm is not '':\n",
    "            bm_map = self.da_bm.sel(time=np.datetime64(self.date_picker.value)).hvplot(x='x',y='y',\n",
    "                                                                                       tiles='EsriImagery',\n",
    "                                                                                       crs=ccrs.UTM(13),\n",
    "                                                                                       cmap='inferno', \n",
    "                                                                                       clim=(100, 1000), \n",
    "                                                                                       colorbar=False,\n",
    "                                                                                       sizing_mode='stretch_both',\n",
    "                                                                                       width=350,\n",
    "                                                                                       title='BM: '+str(self.date_picker.value))#.opts(height=int(500*1.5), width=int(750*1.5))\n",
    "            return bm_map\n",
    "        else:\n",
    "            return('')\n",
    "    \n",
    "    @pm.depends('date_picker.param', 'thresh_picker.param')\n",
    "    def load_thresh(self):\n",
    "        if self.da_bm is not '':\n",
    "            da_thresh = pred_bm_thresh(self.da_bm, self.da_se, self.thresh_picker.value)      \n",
    "            thresh_map = da_thresh.sel(time=np.datetime64(self.date_picker.value)).hvplot(x='x', y='y', \n",
    "                                                                                          tiles='EsriImagery', \n",
    "                                                                                          crs=ccrs.UTM(13),\n",
    "                                                                                          cmap='YlOrRd', \n",
    "                                                                                          clim=(0.05, 0.95),\n",
    "                                                                                          colorbar=False,\n",
    "                                                                                          data_aspect=0.6).opts(responsive=True,\n",
    "                                                                                                                xticks=None,\n",
    "                                                                                                                yticks=None)\n",
    "            return thresh_map\n",
    "        else:\n",
    "            return('')\n",
    "        \n",
    "    @pm.depends('access_data')\n",
    "    def showdata(self):\n",
    "        return(pn.pane.HTML(self.data,sizing_mode='stretch_both',max_width=250))\n",
    "app = HLS_BM_Explorer(name='Central Plains Experimental Range: HLS Biomass')\n",
    "\n",
    "template_theme = pn.template.MaterialTemplate(title='Central Plains Experimental Range: HLS Biomass',\n",
    "                                              logo='https://ltar.ars.usda.gov/wp-content/uploads/2018/10/usda_ltar_logo_header_v3.png',\n",
    "                                              header_color='grey',header_background='#80b1ed')\n",
    "template_theme.sidebar.append(pn.Column(app.username_input,\n",
    "                                        app.password_input,\n",
    "                                        app.d_range,\n",
    "                                        pn.panel(app.param.action),\n",
    "                                        sizing_mode='stretch_both',\n",
    "                                        name=\"Download Options\",\n",
    "                                        css_classes=['panel-widget-box']))\n",
    "template_theme.sidebar.append(pn.Column(app.date_picker, \n",
    "                                        app.thresh_picker,\n",
    "                                        sizing_mode='stretch_both'))\n",
    "template_theme.main.append(pn.Card(pn.Tabs(('Cover', app.load_cov),\n",
    "                                           ('Biomass', app.load_bm),\n",
    "                                           ('Biomass threshold', app.load_thresh)),\n",
    "                                   title='Maps',\n",
    "                                   sizing_mode='stretch_both',\n",
    "                                   header_background='#80b1ed'))\n",
    "template_theme.main.append(pn.Card(app.showdata,\n",
    "                                   title='Xarray Object',\n",
    "                                   sizing_mode='stretch_both',\n",
    "                                   header_background='#80b1ed',\n",
    "                                   collapsed=True))\n",
    "#template_theme.show(port=9000)\n",
    "template_theme.servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
